{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute path\n",
    "absPath = str(Path(os.path.abspath(os.getcwd())).absolute())\n",
    "datasetsPath = os.path.join(absPath, \"datasets\")\n",
    "rdfPath = os.path.join(absPath, \"rdf\")\n",
    "\n",
    "# Create dataset directory if not exists\n",
    "if not os.path.exists(datasetsPath):\n",
    "    os.mkdir(datasetsPath)\n",
    "\n",
    "# Create RDF directory if not exists\n",
    "if not os.path.exists(rdfPath):\n",
    "    os.mkdir(rdfPath)\n",
    "\n",
    "# Setup datasets paths\n",
    "spotifyChartsPath = os.path.join(datasetsPath, \"reducedSpotifyCharts.csv\")\n",
    "genresPath = os.path.join(datasetsPath, \"genres.csv\")\n",
    "marketsPath = os.path.join(datasetsPath, \"markets.csv\")\n",
    "tracksPath = os.path.join(datasetsPath, \"tracks.csv\")\n",
    "albumsPath = os.path.join(datasetsPath, \"albums.csv\")\n",
    "artistsPath = os.path.join(datasetsPath, \"artists.csv\")\n",
    "peoplePath = os.path.join(datasetsPath, \"people.csv\")\n",
    "\n",
    "# Setup Turtle paths\n",
    "genresTTLPath = os.path.join(rdfPath, \"genres.ttl\")\n",
    "marketsTTLPath = os.path.join(rdfPath, \"markets.ttl\")\n",
    "tracksTTLPath = os.path.join(rdfPath, \"tracks.ttl\")\n",
    "albumsTTLPath = os.path.join(rdfPath, \"albums.ttl\")\n",
    "artistsTTLPath = os.path.join(rdfPath, \"artists.ttl\")\n",
    "peopleTTLPath = os.path.join(rdfPath, \"people.ttl\")\n",
    "appearanceTTLPath = os.path.join(rdfPath, \"appearance.ttl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the ontologies namespaces not known by RDFlib\n",
    "\n",
    "# Country Ontology\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "\n",
    "# Spotify Ontology\n",
    "SO = Namespace(\"https://www.dei.unipd.it/~martinelli/spotify/spotifyOntology#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"so\", SO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "albums = pd.read_csv(albumsPath, sep=\",\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the album DataFrame\n",
    "for albumID, row in albums.iterrows():\n",
    "    # Create the node to add to the Graph \n",
    "    Album = URIRef(SO[albumID])\n",
    "\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Album, RDF.type, SO.Album))\n",
    "\n",
    "    # Add the name of the album\n",
    "    g.add((Album, SO[\"name\"], Literal(row[\"title\"], datatype=XSD.string)))\n",
    "    \n",
    "    # Add the total tracks of the album\n",
    "    g.add((Album, SO[\"totalTracks\"], Literal(row[\"total_tracks\"], datatype=XSD.int)))\n",
    "\n",
    "    # Manage release date taking into account release precision\n",
    "    releaseDate = row[\"release_date\"]\n",
    "    if(row[\"release_date_precision\"]==\"year\"):\n",
    "        releaseDate += \"-01-01\"\n",
    "    elif(row[\"release_date_precision\"]==\"month\"):\n",
    "        releaseDate += \"-01\"\n",
    "    \n",
    "    # Add the release date of the album\n",
    "    g.add((Album, SO[\"releaseDate\"], Literal(releaseDate, datatype=XSD.date)))    \n",
    "    \n",
    "    # Add album type\n",
    "    albumType = URIRef(SO[row[\"album_type\"]])\n",
    "    g.add((Album, SO[\"isTypeOf\"], albumType))  \n",
    "\n",
    "    # Load countries as array\n",
    "    countries = row[\"available_countries\"].split(\",\") if not pd.isnull(row[\"available_countries\"]) else []\n",
    "\n",
    "    for country in countries:\n",
    "        # Create the RDF node\n",
    "        Country = URIRef(CNS[country.lower()])\n",
    "\n",
    "        # Add the edge connecting the Album and the Country \n",
    "        g.add((Album, SO[\"isAvailableIn\"], Country))  \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the data in the Turtle format\n",
    "print(\"[ðŸ’¾] SAVING\")\n",
    "with open(albumsTTLPath, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(g.serialize(format=\"turtle\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22d38fa0cb949c4d83b127034afdff90d77a7338f5681221558c482c7c131893"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
